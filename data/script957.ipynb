{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "version": "3.6.3", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py"}}, "cells": [{"metadata": {}, "cell_type": "markdown", "source": ["# I am predicting reviews for null values in dataset using already given reviews."]}, {"metadata": {"_cell_guid": "3308441e-d2c1-4271-9e47-f9217a2a15f6", "_uuid": "1fb38abd989c00734aafadb7290482db5484e067"}, "cell_type": "code", "execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": []}, {"metadata": {"_cell_guid": "d2a5ef6c-143c-46c3-a7bb-802cc36269d4", "_uuid": "5fd2c5b476c3371905f898e0cf65b695ea9a7b4d"}, "cell_type": "markdown", "source": ["## Importing Libraries"]}, {"metadata": {"_cell_guid": "e23115dc-bf4f-4f75-8eee-9ea94bdf9c38", "_uuid": "7bcd1e07ca092777802d58553fed4db595cf709c", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import matplotlib as mpl\n", "import nltk.classify.util\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn import metrics\n", "from sklearn.metrics import roc_curve, auc\n", "from nltk.classify import NaiveBayesClassifier\n", "import numpy as np\n", "import re\n", "import string\n", "import nltk\n", "%matplotlib inline"], "outputs": []}, {"metadata": {"_cell_guid": "ab3c2744-9bab-431e-a1df-32437a143e3d", "_uuid": "118bb51d694e5ec0b4f34d96a135966dc4654bd4"}, "cell_type": "code", "execution_count": null, "source": ["temp = pd.read_csv(r\"../input/7817_1.csv\")\n", "temp.head()"], "outputs": []}, {"metadata": {"_cell_guid": "d989623e-c622-45bd-8232-450f7c06ae01", "_uuid": "0f433f3faf598008d06f3aeb0898aec196abd6c7"}, "cell_type": "code", "execution_count": null, "source": ["permanent = temp[['reviews.rating' , 'reviews.text' , 'reviews.title' , 'reviews.username']]\n", "print(permanent.isnull().any()) #Checking for null values\n", "permanent.head()\n"], "outputs": []}, {"metadata": {"_cell_guid": "fa18f4f5-020c-4676-9325-de8d39488570", "_uuid": "5d9d31976e08c35ee092bba77f80aa9badbf35c3"}, "cell_type": "markdown", "source": ["## Filtering null values"]}, {"metadata": {"_cell_guid": "8d90d3f2-778f-4228-a950-aa3ed439a980", "_uuid": "f6d87f465ec602326168512617dfc72f69860e15"}, "cell_type": "code", "execution_count": null, "source": ["check =  permanent[permanent[\"reviews.rating\"].isnull()]\n", "check.head()"], "outputs": []}, {"metadata": {"_cell_guid": "4774bce2-b3fd-40b1-99b3-9589655fd61c", "_uuid": "e8a79c132dae52eba3fcad5935cb50f48820d3c5"}, "cell_type": "markdown", "source": ["## Filtering not null values"]}, {"metadata": {"_cell_guid": "ef1db1ef-32c5-400a-8956-88bc33adc3c2", "_uuid": "0619937b511a032295187fe76b368adbca2a8c49"}, "cell_type": "code", "execution_count": null, "source": ["senti= permanent[permanent[\"reviews.rating\"].notnull()]\n", "permanent.head()"], "outputs": []}, {"metadata": {"_cell_guid": "fb75db3a-585b-4de7-9607-c9f3035283f2", "_uuid": "d92a6d52db6097b71f35824c93342920026b4195"}, "cell_type": "markdown", "source": ["## Classifying text as postive and negative"]}, {"metadata": {"_cell_guid": "41696a53-19f1-4275-a5f9-8f2be0109afd", "_uuid": "3e73d8ce154f6e0ccaa7b712d8f05acc19b0d978"}, "cell_type": "code", "execution_count": null, "source": ["senti[\"senti\"] = senti[\"reviews.rating\"]>=4\n", "senti[\"senti\"] = senti[\"senti\"].replace([True , False] , [\"pos\" , \"neg\"])"], "outputs": []}, {"metadata": {"_cell_guid": "8f143c16-6ac1-45d2-ae1a-85906f21adb0", "_uuid": "1c678f15281647e1acba8d5c2f5992933d058c0a"}, "cell_type": "markdown", "source": ["## Count of reviews"]}, {"metadata": {"_cell_guid": "89c5d3fc-3531-40a8-a0b8-1ab614fb6acd", "_uuid": "770aca195535cf73923aaef37bf24745ec54514e"}, "cell_type": "code", "execution_count": null, "source": ["senti[\"senti\"].value_counts().plot.bar()"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["As we can see data is unbalanced so this will create problem for model but, will take this data as it is and will predict our reviews."]}, {"metadata": {"_cell_guid": "c56d24f3-eff5-45f5-910e-162a0b03c710", "_uuid": "aaaf33172865ca5cc532c1c572b8cf1d07f9cd92"}, "cell_type": "markdown", "source": ["## Cleaning text"]}, {"metadata": {"_cell_guid": "2fea4cdc-cb0b-4e01-9b67-3fc8471d1335", "_uuid": "9ac6b57241511ac14d574531f7161ddcdb00cc8b"}, "cell_type": "code", "execution_count": null, "source": ["import nltk.classify.util\n", "from nltk.classify import NaiveBayesClassifier\n", "import numpy as np\n", "import re\n", "import string\n", "import nltk\n", "\n", "cleanup_re = re.compile('[^a-z]+')\n", "def cleanup(sentence):\n", "    sentence = sentence.lower()\n", "    sentence = cleanup_re.sub(' ', sentence).strip()\n", "    #sentence = \" \".join(nltk.word_tokenize(sentence))\n", "    return sentence\n", "\n", "senti[\"Summary_Clean\"] = senti[\"reviews.text\"].apply(cleanup)\n", "check[\"Summary_Clean\"] = check[\"reviews.text\"].apply(cleanup)\n"], "outputs": []}, {"metadata": {"_cell_guid": "a35ea44f-1edc-4730-9e5b-93e250a2ccfe", "_uuid": "c7e93168c642d5c091405ce85b0744de5c0ca354"}, "cell_type": "markdown", "source": ["## Splitting Train and Test Data"]}, {"metadata": {"_cell_guid": "af7c6e3d-bdb5-4dbb-8e5d-99e1f869601d", "_uuid": "f843f7a6c8731061183855b15a23a806754ce7a6", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["split = senti[[\"Summary_Clean\" , \"senti\"]]\n", "train=split.sample(frac=0.8,random_state=200)\n", "test=split.drop(train.index)"], "outputs": []}, {"metadata": {"_cell_guid": "7fbe6570-b5e9-4845-8a03-d2c67927581c", "_uuid": "27058ae188493485ca449bac9871de9437da3d05"}, "cell_type": "markdown", "source": ["## Feature Extracter for NLTK Naive bayes classifier"]}, {"metadata": {"_cell_guid": "8ed22181-6e32-4739-bb66-36a8428906d1", "_uuid": "5f2f34d01b7014bcdb9cd67133490fe8d48c9b76", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["def word_feats(words):\n", "    features = {}\n", "    for word in words:\n", "        features [word] = True\n", "    return features\n"], "outputs": []}, {"metadata": {"_cell_guid": "8657105a-6d77-4765-8e54-6ef8ab1012ba", "_uuid": "75d8848661e27e8d4dde26a15e971368be3c008f"}, "cell_type": "code", "execution_count": null, "source": ["train[\"words\"] = train[\"Summary_Clean\"].str.lower().str.split()\n", "test[\"words\"] = test[\"Summary_Clean\"].str.lower().str.split()\n", "check[\"words\"] = check[\"Summary_Clean\"].str.lower().str.split()\n", "\n", "train.index = range(train.shape[0])\n", "test.index = range(test.shape[0])\n", "check.index = range(check.shape[0])\n", "prediction =  {} ## For storing results of different classifiers\n", "\n", "train_naive = []\n", "test_naive = []\n", "check_naive = []\n", "\n", "for i in range(train.shape[0]):\n", "    train_naive = train_naive +[[word_feats(train[\"words\"][i]) , train[\"senti\"][i]]]\n", "for i in range(test.shape[0]):\n", "    test_naive = test_naive +[[word_feats(test[\"words\"][i]) , test[\"senti\"][i]]]\n", "for i in range(check.shape[0]):\n", "    check_naive = check_naive +[word_feats(check[\"words\"][i])]\n", "\n", "\n", "classifier = NaiveBayesClassifier.train(train_naive)\n", "print(\"NLTK Naive bayes Accuracy : {}\".format(nltk.classify.util.accuracy(classifier , test_naive)))\n", "classifier.show_most_informative_features(5)\n"], "outputs": []}, {"metadata": {"_cell_guid": "5ee3bb7e-55b8-408a-8aee-ef8f5123bf94", "_uuid": "ad1d1c3c4520884fe350be4a10e7992d792122fe"}, "cell_type": "markdown", "source": ["## predicting result of nltk classifier"]}, {"metadata": {"_cell_guid": "aa113bf9-2b13-4fbb-9201-82ad8ee1d9e0", "_uuid": "2f7a02131c869647522aafeebc5ca18819621e18"}, "cell_type": "code", "execution_count": null, "source": ["y =[]\n", "only_words= [test_naive[i][0] for i in range(test.shape[0])]\n", "for i in range(test.shape[0]):\n", "    y = y + [classifier.classify(only_words[i] )]\n", "prediction[\"Naive\"]= np.asarray(y)\n", "\n", "y1 = []\n", "for i in range(check.shape[0]):\n", "    y1 = y1 + [classifier.classify(check_naive[i] )]\n", "\n", "check[\"Naive\"] = y1"], "outputs": []}, {"metadata": {"_cell_guid": "9358d370-3d07-4052-b9f7-68177915bf0c", "_uuid": "739a8abfe26a70358ddb274cab0c3acb996e0a27"}, "cell_type": "markdown", "source": ["## Now we are bulding Countvector and Tfidf vector for train , test ,check data"]}, {"metadata": {"_cell_guid": "8f9f3477-896b-4de7-a70a-09724bd5b929", "_uuid": "e278d75a576fed5542d677750f1b68ebbd947061", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["from wordcloud import STOPWORDS\n", "\n", "from sklearn.feature_extraction.text import TfidfTransformer\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "stopwords = set(STOPWORDS)\n", "stopwords.remove(\"not\")\n", "\n", "count_vect = CountVectorizer(min_df=2 ,stop_words=stopwords , ngram_range=(1,3))\n", "tfidf_transformer = TfidfTransformer()\n", "\n", "X_train_counts = count_vect.fit_transform(train[\"Summary_Clean\"])        \n", "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n", "\n", "\n", "X_new_counts = count_vect.transform(test[\"Summary_Clean\"])\n", "X_test_tfidf = tfidf_transformer.transform(X_new_counts)\n", "\n", "checkcounts = count_vect.transform(check[\"Summary_Clean\"])\n", "checktfidf = tfidf_transformer.transform(checkcounts)\n", "\n", "\n"], "outputs": []}, {"metadata": {"_cell_guid": "a72af24a-8afd-46c2-8a9b-c0f34e06a8c3", "_uuid": "2a55ae968bb538fed04ec512cfc76f46a2e76c9d"}, "cell_type": "markdown", "source": ["## Fitiing Multinomial NB\n"]}, {"metadata": {"_cell_guid": "4fbe128a-83ef-4cad-9161-e8e0bf4f0275", "_uuid": "3240a0e0dc18bf3ed26e16846109145b815c5aac"}, "cell_type": "code", "execution_count": null, "source": ["from sklearn.naive_bayes import MultinomialNB\n", "model1 = MultinomialNB().fit(X_train_tfidf , train[\"senti\"])\n", "prediction['Multinomial'] = model1.predict(X_test_tfidf)\n", "print(\"Multinomial Accuracy : {}\".format(model1.score(X_test_tfidf , test[\"senti\"])))\n", "\n", "check[\"multi\"] = model1.predict(checktfidf)## Predicting Sentiment for Check which was Null values for rating\n"], "outputs": []}, {"metadata": {"_cell_guid": "830c637b-c970-4de0-8bc5-874afc9ce233", "_uuid": "de97924ca8a7070fbae7f4e3cfee42917353f1be"}, "cell_type": "markdown", "source": ["## Fitiing Bernouli NB\n"]}, {"metadata": {"_cell_guid": "d6bf2247-112e-4e73-a5f0-5a9d436bceba", "_uuid": "cc7784b7292590d9cc200bb274ea65785c40bca5", "scrolled": true}, "cell_type": "code", "execution_count": null, "source": ["from sklearn.naive_bayes import BernoulliNB\n", "model2 = BernoulliNB().fit(X_train_tfidf,train[\"senti\"])\n", "prediction['Bernoulli'] = model2.predict(X_test_tfidf)\n", "print(\"Bernoulli Accuracy : {}\".format(model2.score(X_test_tfidf , test[\"senti\"])))\n", "\n", "check[\"Bill\"] = model2.predict(checktfidf)## Predicting Sentiment for Check which was Null values for rating\n"], "outputs": []}, {"metadata": {"_cell_guid": "2f1765a0-6300-47da-a3ae-5e6c54e4fa61", "_uuid": "4e408529704d1472967dfd353432e5fc2dfa6015"}, "cell_type": "markdown", "source": ["## Fitiing LogisticRegression"]}, {"metadata": {"_cell_guid": "b1ca2b0b-6dc3-4e4b-a604-598c40d2c35e", "_uuid": "9fca90804b94b6191d3f8d7d13f9588ae9d8d346"}, "cell_type": "code", "execution_count": null, "source": ["from sklearn import linear_model\n", "logreg = linear_model.LogisticRegression(solver='lbfgs' , C=10000)\n", "logistic = logreg.fit(X_train_tfidf, train[\"senti\"])\n", "prediction['LogisticRegression'] = logreg.predict(X_test_tfidf)\n", "print(\"Logistic Regression Accuracy : {}\".format(logreg.score(X_test_tfidf , test[\"senti\"])))\n", "\n", "check[\"log\"] = logreg.predict(checktfidf)## Predicting Sentiment for Check which was Null values for rating\n"], "outputs": []}, {"metadata": {"_cell_guid": "1f3789b6-eae3-4f66-a1b2-fe774db287cf", "_uuid": "b5e5368e9a1ab45dde7f9809a744e42a732ce9ec"}, "cell_type": "markdown", "source": ["## Getting most occuring words in train set\n"]}, {"metadata": {"_cell_guid": "d935f7e8-f500-451b-a498-bae5ef5f1792", "_uuid": "1b184162bd29faf2e686ecce1dd9712a90705556", "scrolled": true}, "cell_type": "code", "execution_count": null, "source": ["words = count_vect.get_feature_names()\n", "feature_coefs = pd.DataFrame(\n", "    data = list(zip(words, logistic.coef_[0])),\n", "    columns = ['feature', 'coef'])\n", "feature_coefs.sort_values(by=\"coef\")"], "outputs": []}, {"metadata": {"_cell_guid": "932b8a80-ddb8-491c-8a67-cc5171126de0", "_uuid": "8c68f174a9934d47bcc72aaf9cd66b3d522c8e8c"}, "cell_type": "markdown", "source": ["## Lets find out which classifier is doing what"]}, {"metadata": {"_cell_guid": "7f6519c1-8144-4e27-af7a-94fcf3010e37", "_uuid": "c5d58f9f66cfea47cda26c53730bfa03b1ea6c3e"}, "cell_type": "code", "execution_count": null, "source": ["def formatt(x):\n", "    if x == 'neg':\n", "        return 0\n", "    return 1\n", "vfunc = np.vectorize(formatt)\n", "\n", "cmp = 0\n", "colors = ['b', 'g', 'y', 'm', 'k']\n", "for model, predicted in prediction.items():\n", "    false_positive_rate, true_positive_rate, thresholds = roc_curve(test[\"senti\"].map(formatt), vfunc(predicted))\n", "    roc_auc = auc(false_positive_rate, true_positive_rate)\n", "    plt.plot(false_positive_rate, true_positive_rate, colors[cmp], label='%s: AUC %0.2f'% (model,roc_auc))\n", "    cmp += 1\n", "\n", "plt.title('Classifiers comparaison with ROC')\n", "plt.legend(loc='lower right')\n", "plt.plot([0,1],[0,1],'r--')\n", "plt.xlim([-0.1,1.2])\n", "plt.ylim([-0.1,1.2])\n", "plt.ylabel('True Positive Rate')\n", "plt.xlabel('False Positive Rate')\n", "plt.show()"], "outputs": []}, {"metadata": {"_cell_guid": "3a0e832c-ac72-4bb4-abee-6ea1c057b554", "_uuid": "6c732f04807cc36e931ba54a0f5de7af3039d615"}, "cell_type": "markdown", "source": ["## Lets see precision  and recall  of  different  classifiers\n"]}, {"metadata": {"_cell_guid": "685fabad-8cc6-4823-82db-5b85d41e6b07", "_uuid": "8a6d626be55be9763aeec43881cb0e99268e3664"}, "cell_type": "markdown", "source": ["![Precision_Recall](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png)"]}, {"metadata": {"_cell_guid": "1aef6c14-a525-4880-992a-9de2d5d51987", "_uuid": "cd8b8d9474933bd0ec03a112caaf40d3118c15a8"}, "cell_type": "code", "execution_count": null, "source": ["keys = prediction.keys()\n", "for key in keys:\n", "    print(\" {}:\".format(key))\n", "    print(metrics.classification_report(test[\"senti\"], prediction.get(key), target_names = [\"positive\", \"negative\"]))\n", "    print(\"\\n\")"], "outputs": []}, {"metadata": {"_cell_guid": "b6e0a360-0679-4a9c-b926-b62d29711dec", "_uuid": "57ccfe020ea6bd0f999026a24aae722e5aee0905"}, "cell_type": "markdown", "source": ["## Let test our classifiers with some handwritten samples\n"]}, {"metadata": {"_cell_guid": "b7c724c3-8371-4668-8c7a-e1647389b4e3", "_uuid": "b50248fed62b75959a19a020e3bdbe1816a801aa"}, "cell_type": "code", "execution_count": null, "source": ["def test_sample(model, sample):\n", "    sample_counts = count_vect.transform([sample])\n", "    sample_tfidf = tfidf_transformer.transform(sample_counts)\n", "    result = model.predict(sample_tfidf)[0]\n", "    prob = model.predict_proba(sample_tfidf)[0]\n", "    print(\"Sample estimated as %s: negative prob %f, positive prob %f\" % (result.upper(), prob[0], prob[1]))\n", "\n", "test_sample(logreg, \"The product was good and easy to  use\")\n", "test_sample(logreg, \"the whole experience was horrible and product is worst\")\n", "test_sample(logreg, \"product is not good\")\n"], "outputs": []}, {"metadata": {"_cell_guid": "a308cc57-0854-4399-916f-53f3b77b1931", "_uuid": "e20eac56a0fc3f288bc5da068ce8cb304118ea62"}, "cell_type": "markdown", "source": ["## Here is predicted valuesof classifiers for check on the basis of review text"]}, {"metadata": {"_cell_guid": "8cbeb076-c8e9-4ade-b3a6-a7fe840c5b6c", "_uuid": "5b6b4a8a622fc316bd90020b00e4b5a9174bd249"}, "cell_type": "code", "execution_count": null, "source": ["check.head(10)"], "outputs": []}, {"metadata": {"_cell_guid": "40e0b5a2-02e2-4f87-a0a0-b9c159363171", "_uuid": "b73de1dc5f6866c5b9e4f6717c5ca8b3bba3930f"}, "cell_type": "code", "execution_count": null, "source": ["from wordcloud import WordCloud, STOPWORDS\n", "stopwords = set(STOPWORDS)\n", "\n", "\n", "mpl.rcParams['font.size']=12                #10 \n", "mpl.rcParams['savefig.dpi']=100             #72 \n", "mpl.rcParams['figure.subplot.bottom']=.1 \n", "\n", "\n", "def show_wordcloud(data, title = None):\n", "    wordcloud = WordCloud(\n", "        background_color='white',\n", "        stopwords=stopwords,\n", "        max_words=300,\n", "        max_font_size=40, \n", "        scale=3,\n", "        random_state=1 # chosen at random by flipping a coin; it was heads\n", "        \n", "    ).generate(str(data))\n", "    \n", "    fig = plt.figure(1, figsize=(15, 15))\n", "    plt.axis('off')\n", "    if title: \n", "        fig.suptitle(title, fontsize=20)\n", "        fig.subplots_adjust(top=2.3)\n", "\n", "    plt.imshow(wordcloud)\n", "    plt.show()\n", "    \n", "show_wordcloud(senti[\"Summary_Clean\"])\n"], "outputs": []}, {"metadata": {"_cell_guid": "06904773-5d5a-42c2-b1ef-b090640de2c2", "_uuid": "94dd43ba61c11b6c7b13663d49b20b2153ef05c3"}, "cell_type": "code", "execution_count": null, "source": ["show_wordcloud(senti[\"Summary_Clean\"][senti.senti == \"pos\"] , title=\"Postive Words\")"], "outputs": []}, {"metadata": {"_cell_guid": "4fa3c881-b7ef-41ac-ad8d-52f221cf7315", "_uuid": "b748fdc88a520b5e9989349efe24b2ce572e71e0"}, "cell_type": "code", "execution_count": null, "source": ["show_wordcloud(senti[\"Summary_Clean\"][senti.senti == \"neg\"] , title=\"Negitive words\")"], "outputs": []}, {"metadata": {"_cell_guid": "01146775-1a28-428e-9351-9e8a6cf03b98", "_uuid": "723db44c7421c6d08229b1e53dcfb4db4fe32090", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": [], "outputs": []}], "nbformat": 4, "nbformat_minor": 1}