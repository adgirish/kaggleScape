{"cells":[{"metadata":{"_cell_guid":"e9856b7f-cefa-4b9e-bc75-fde723dd0005","_uuid":"967401456df79d757b44efc9a65d273dd6673216"},"cell_type":"markdown","source":"# Intro\n\n**This is Lesson 4 in the [Deep Learning](https://www.kaggle.com/learn/deep-learning) track**  \n\nAt the end of this lesson, you will be able to use transfer learning to build highly accurate computer vision models for your custom purposes, even when you have relatively little data.\n\n# Lesson\n"},{"metadata":{"_cell_guid":"5f246c0b-d4a7-4c80-98fe-5e1ce0f47234","_kg_hide-input":true,"_uuid":"c641bd4ace694c5329e4e122434bede40251db3a","trusted":true},"cell_type":"code","source":"from IPython.display import YouTubeVideo\nYouTubeVideo('mPFq5KMxKVw', width=800, height=450)","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"099283e5-c30d-450c-95b5-8c560e3a13c5","_uuid":"1554f3533a3559d955720585333d5c357c500608"},"cell_type":"markdown","source":"# Sample Code\n\n### Specify Model"},{"metadata":{"_cell_guid":"adea2cce-46da-4482-8ea0-c7128b560fed","_kg_hide-output":true,"_uuid":"88e43f83b57eb37825e7a7b8ab3f4041686a32cf","trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\nnum_classes = 2\nresnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nmy_new_model = Sequential()\nmy_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nmy_new_model.add(Dense(num_classes, activation='softmax'))\n\n# Say not to train first layer (ResNet) model. It is already trained\nmy_new_model.layers[0].trainable = False","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"a70edb39-61fc-4912-9101-090f3068dd18","_uuid":"9762b669e09967d36e625bde91279cf80d2f7178"},"cell_type":"markdown","source":"### Compile Model"},{"metadata":{"_cell_guid":"defc5fc9-af8e-4891-b41b-a38a1608bf09","_kg_hide-output":true,"_uuid":"f6bd8ba793ed55dad8cc016612f07f9ecd656007","collapsed":true,"trusted":true},"cell_type":"code","source":"my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"ff9b7200-7a43-4c7d-8b89-36d4557a41bc","_uuid":"1bde4d685879252d1346f35d6869c22b8be42f32"},"cell_type":"markdown","source":"### Fit Model"},{"metadata":{"_cell_guid":"07d8e9c7-043e-4b2a-a7c4-73791b283caf","_uuid":"48631321426fae639556c7ca0407927f2fae84d9","trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\nimage_size = 224\n# The ImageDataGenerator was previously generated with\n# data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n# recent changes in keras require that we use the following instead:\ndata_generator = ImageDataGenerator() \n\ntrain_generator = data_generator.flow_from_directory(\n        '../input/urban-and-rural-photos/rural_and_urban_photos/train',\n        target_size=(image_size, image_size),\n        batch_size=24,\n        class_mode='categorical')\n\nvalidation_generator = data_generator.flow_from_directory(\n        '../input/urban-and-rural-photos/rural_and_urban_photos/val',\n        target_size=(image_size, image_size),\n        class_mode='categorical')\n\nmy_new_model.fit_generator(\n        train_generator,\n        steps_per_epoch=3,\n        validation_data=validation_generator,\n        validation_steps=1)","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"382b849d-dd62-461b-a921-4786126746b6","_uuid":"523fa8ad8c1ff500f3f01e53d18948e9f93d6e67"},"cell_type":"markdown","source":"### Note on Results:\nThe printed validation accuracy can be meaningfully better than the training accuracy at this stage. This can be puzzling at first.\n\nIt occurs because the training accuracy was calculated at multiple points as the network was improving (the numbers in the convolutions were being updated to make the model more accurate).  The network was still quite when the model saw the first training images, since the weights hadn't been trained/improved much yet.  Those first training results were averaged into the measure above.\n\nThe validation loss and accuracy measures were calculated **after** the model had gone through all the data.  So the network had been fully trained when these scores were calculated.\n\nThis isn't a serious issue in practice, and we tend not to worry about it."},{"metadata":{"_cell_guid":"e8cf7b2b-fd3a-40c2-bb25-a4b5f1d28c21","_uuid":"1e766f84444b79aa99c665e3482a15c3a9b0b56d"},"cell_type":"markdown","source":"# Your Turn\n[Write your own kernel to do transfer learning](https://www.kaggle.com/dansbecker/exercise-using-transfer-learning/).\n\n# Keep Going\nAfter the exercise, you move on to [data augmentation](https://www.kaggle.com/dansbecker/data-augmentation/).  It's a clever (and easy) trick to improve your models."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}