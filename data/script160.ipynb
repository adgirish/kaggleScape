{"metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"mimetype": "text/x-python", "version": "3.6.3", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3"}}, "cells": [{"metadata": {"collapsed": true, "_uuid": "084f41cecad64f0b3cf67d93fd9dd44255c47ecf", "_cell_guid": "6d675bbf-4ca5-4d5b-83dc-737be7d9c406"}, "cell_type": "code", "outputs": [], "source": ["%%time\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn import *\n", "import lightgbm as lgb\n", "import random\n", "\n", "train = pd.read_json(\"../input/statoil-iceberg-classifier-challenge/train.json\").fillna(-1.0).replace('na', -1.0)\n", "test = pd.read_json(\"../input/statoil-iceberg-classifier-challenge/test.json\").fillna(-1.0).replace('na', -1.0)\n", "train['angle_l'] = train['inc_angle'].apply(lambda x: len(str(x))) <= 7\n", "test['angle_l'] = test['inc_angle'].apply(lambda x: len(str(x))) <= 7\n", "train['null_angle'] = (train['inc_angle']==-1).values\n", "test['null_angle'] = (test['inc_angle']==-1).values\n", "x1 = train[train['inc_angle']!= -1.0]\n", "x2 = train[train['inc_angle']== -1.0]\n", "del train;\n", "print(x1.values.shape, x2.values.shape)"], "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "f5023d42a6fd495a7c73bcfb5a5491054546ed74", "_cell_guid": "1c884a45-eb5c-4093-ad54-a07cd57d7166"}, "cell_type": "code", "outputs": [], "source": ["%%time\n", "pca_b1 = decomposition.PCA(n_components=50, whiten=False, random_state=12)\n", "pca_b2 = decomposition.PCA(n_components=50, whiten=False, random_state=13)\n", "etc = ensemble.ExtraTreesRegressor(n_estimators=200, max_depth=7, n_jobs=-1, random_state=14)\n", "\n", "band1 = [np.array(band).astype(np.float32).flatten() for band in x1[\"band_1\"]]\n", "band2 = [np.array(band).astype(np.float32).flatten() for band in x1[\"band_2\"]]\n", "band1 = pd.DataFrame(pca_b1.fit_transform(band1))\n", "band1.columns = [str(c)+'_1' for c in band1.columns]\n", "band2 = pd.DataFrame(pca_b2.fit_transform(band2))\n", "band2.columns = [str(c)+'_2' for c in band2.columns]\n", "features = pd.concat((band1, band2), axis=1, ignore_index=True)\n", "etc.fit(features, x1.inc_angle)\n", "\n", "band1 = [np.array(band).astype(np.float32).flatten() for band in x2[\"band_1\"]]\n", "band2 = [np.array(band).astype(np.float32).flatten() for band in x2[\"band_2\"]]\n", "band1 = pd.DataFrame(pca_b1.transform(band1))\n", "band1.columns = [str(c)+'_1' for c in band1.columns]\n", "band2 = pd.DataFrame(pca_b2.fit_transform(band2))\n", "band2.columns = [str(c)+'_2' for c in band2.columns]\n", "features = pd.concat((band1, band2), axis=1, ignore_index=True)\n", "x2['inc_angle'] = etc.predict(features)\n", "\n", "train = pd.concat((x1, x2), axis=0, ignore_index=True).reset_index(drop=True)\n", "del x1; del x2;\n", "print(train.values.shape)\n", "train.head()"], "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "b0eb5976b884864310911aa746cc2443ca34fd16", "_cell_guid": "fa96f0d8-f118-4358-ac56-f2fde71fbcd5"}, "cell_type": "code", "outputs": [], "source": ["%%time\n", "pca_b1 = decomposition.PCA(n_components=50, whiten=True, random_state=15)\n", "pca_b2 = decomposition.PCA(n_components=50, whiten=True, random_state=16)\n", "pca_b3 = decomposition.PCA(n_components=50, whiten=True, random_state=17)\n", "pca_b4 = decomposition.PCA(n_components=50, whiten=True, random_state=18)\n", "\n", "band1 = [np.array(band).astype(np.float32).flatten() for band in train[\"band_1\"]]\n", "band2 = [np.array(band).astype(np.float32).flatten() for band in train[\"band_2\"]]\n", "pd_band1 = pd.DataFrame(band1)\n", "pd_band2 = pd.DataFrame(band2)\n", "pd_band3 = pd.DataFrame(np.dot(np.diag(train['inc_angle'].values), ((pd_band1 + pd_band2) / 2)))\n", "pd_band4 = pd.DataFrame(np.dot(np.diag(train['inc_angle'].values), ((pd_band1 - pd_band2) / 2)))\n", "band1 = pd.DataFrame(pca_b1.fit_transform(pd_band1))\n", "band1.columns = [str(c)+'_1' for c in band1.columns]\n", "band2 = pd.DataFrame(pca_b2.fit_transform(pd_band2))\n", "band2.columns = [str(c)+'_2' for c in band2.columns]\n", "band3 = pd.DataFrame(pca_b3.fit_transform(pd_band3.values))\n", "band3.columns = [str(c)+'_3' for c in band3.columns]\n", "band4 = pd.DataFrame(pca_b4.fit_transform(pd_band4.values))\n", "band4.columns = [str(c)+'_4' for c in band4.columns]\n", "features = pd.concat((band1, band2, band3, band4), axis=1, ignore_index=True).reset_index(drop=True)\n", "features['inc_angle'] = train['inc_angle']\n", "features['angle_l'] = train['angle_l']\n", "features['null_angle'] = train['null_angle']\n", "features['band1_min'] = pd_band1.min(axis=1, numeric_only=True)\n", "features['band2_min'] = pd_band2.min(axis=1, numeric_only=True)\n", "features['band3_min'] = pd_band3.min(axis=1, numeric_only=True)\n", "features['band4_min'] = pd_band4.min(axis=1, numeric_only=True)\n", "features['band1_max'] = pd_band1.max(axis=1, numeric_only=True)\n", "features['band2_max'] = pd_band2.max(axis=1, numeric_only=True)\n", "features['band3_max'] = pd_band3.max(axis=1, numeric_only=True)\n", "features['band4_max'] = pd_band4.max(axis=1, numeric_only=True)\n", "features['band1_med'] = pd_band1.median(axis=1, numeric_only=True)\n", "features['band2_med'] = pd_band2.median(axis=1, numeric_only=True)\n", "features['band3_med'] = pd_band3.median(axis=1, numeric_only=True)\n", "features['band4_med'] = pd_band4.median(axis=1, numeric_only=True)\n", "features['band1_mea'] = pd_band1.mean(axis=1, numeric_only=True)\n", "features['band2_mea'] = pd_band2.mean(axis=1, numeric_only=True)\n", "features['band3_mea'] = pd_band3.mean(axis=1, numeric_only=True)\n", "features['band4_mea'] = pd_band4.mean(axis=1, numeric_only=True)\n", "del pd_band1; del pd_band2; del pd_band3; del pd_band4\n", "features1 = features.copy()\n", "features.tail()"], "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "a282c2b04995ca56dc0482c590647211687a0e07", "_cell_guid": "face10c2-1ff8-439f-98c4-8b19487fb04c"}, "cell_type": "code", "outputs": [], "source": ["%%time\n", "band1 = [np.array(band).astype(np.float32).flatten() for band in test[\"band_1\"]]\n", "band2 = [np.array(band).astype(np.float32).flatten() for band in test[\"band_2\"]]\n", "pd_band1 = pd.DataFrame(band1)\n", "pd_band2 = pd.DataFrame(band2)\n", "pd_band3 = pd.DataFrame(np.dot(np.diag(test['inc_angle'].values), ((pd_band1 + pd_band2) / 2)))\n", "pd_band4 = pd.DataFrame(np.dot(np.diag(test['inc_angle'].values), ((pd_band1 - pd_band2) / 2)))\n", "band1 = pd.DataFrame(pca_b1.transform(pd_band1))\n", "band1.columns = [str(c)+'_1' for c in band1.columns]\n", "band2 = pd.DataFrame(pca_b2.transform(pd_band2))\n", "band2.columns = [str(c)+'_2' for c in band2.columns]\n", "band3 = pd.DataFrame(pca_b3.transform(pd_band3.values))\n", "band3.columns = [str(c)+'_3' for c in band3.columns]\n", "band4 = pd.DataFrame(pca_b4.fit_transform(pd_band4.values))\n", "band4.columns = [str(c)+'_4' for c in band4.columns]\n", "features = pd.concat((band1, band2, band3, band4), axis=1, ignore_index=True).reset_index(drop=True)\n", "features['inc_angle'] = test['inc_angle']\n", "features['angle_l'] = test['angle_l']\n", "features['null_angle'] = test['null_angle']\n", "features['band1_min'] = pd_band1.min(axis=1, numeric_only=True)\n", "features['band2_min'] = pd_band2.min(axis=1, numeric_only=True)\n", "features['band3_min'] = pd_band3.min(axis=1, numeric_only=True)\n", "features['band4_min'] = pd_band4.min(axis=1, numeric_only=True)\n", "features['band1_max'] = pd_band1.max(axis=1, numeric_only=True)\n", "features['band2_max'] = pd_band2.max(axis=1, numeric_only=True)\n", "features['band3_max'] = pd_band3.max(axis=1, numeric_only=True)\n", "features['band4_max'] = pd_band4.max(axis=1, numeric_only=True)\n", "features['band1_med'] = pd_band1.median(axis=1, numeric_only=True)\n", "features['band2_med'] = pd_band2.median(axis=1, numeric_only=True)\n", "features['band3_med'] = pd_band3.median(axis=1, numeric_only=True)\n", "features['band4_med'] = pd_band4.median(axis=1, numeric_only=True)\n", "features['band1_mea'] = pd_band1.mean(axis=1, numeric_only=True)\n", "features['band2_mea'] = pd_band2.mean(axis=1, numeric_only=True)\n", "features['band3_mea'] = pd_band3.mean(axis=1, numeric_only=True)\n", "features['band4_mea'] = pd_band4.mean(axis=1, numeric_only=True)\n", "del pd_band1; del pd_band2; del pd_band3\n", "features2 = features.copy()\n", "features.tail()"], "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "986c309c91922a83bc51f531d3f582588b5cc49d", "_cell_guid": "8089a2bf-0c3d-432a-9a4f-c844f4ee5485"}, "cell_type": "code", "outputs": [], "source": ["%%time\n", "\n", "lgb_models = []\n", "#xgb_models = []\n", "test['is_iceberg'] = 0.\n", "fold = 5\n", "for i in range(fold):\n", "    np.random.seed(i)\n", "    random.seed(i)\n", "    x1, x2, y1, y2 = model_selection.train_test_split(features1.astype(float), train['is_iceberg'].values, test_size=0.2, random_state=i)\n", "\n", "    #print('XGB...', i)\n", "    #params = {'eta': 0.02, 'max_depth': 4, 'objective': 'multi:softprob', 'eval_metric': 'mlogloss', 'num_class': 2, 'seed': i, 'silent': True}\n", "    #watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n", "    #xgb_models.append(xgb.train(params, xgb.DMatrix(x1, y1), 2000,  watchlist, verbose_eval=500, early_stopping_rounds=200))\n", "\n", "    print('LightGBM...', i)\n", "    params = {'learning_rate': 0.02, 'max_depth': 7, 'boosting_type': 'gbdt', 'objective': 'multiclass', 'metric' : 'multi_logloss', 'is_training_metric': True, 'num_class': 2, 'seed': i}\n", "    lgb_models.append(lgb.train(params, lgb.Dataset(x1, label=y1), 2000, lgb.Dataset(x2, label=y2), verbose_eval=500, early_stopping_rounds=200))\n", "    \n", "    #test['is_iceberg'] += xgb_models[i].predict(xgb.DMatrix(features2), ntree_limit=xgb_models[i].best_ntree_limit)[:, 1]\n", "    test['is_iceberg'] += lgb_models[i].predict(features2, num_iteration=lgb_models[i].best_iteration)[:, 1]"], "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "2ff65fd50c139f846e0520cd0010f7ccb6464201", "_cell_guid": "275675ff-5dd9-43b0-ad0d-3990b6abdff2"}, "cell_type": "code", "outputs": [], "source": ["test['is_iceberg'] = test['is_iceberg'].clip(0.+1e-15,1.-1e-15)\n", "test[['id','is_iceberg']].to_csv(\"submission.csv\", index=False)"], "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "63a2220bfdc413d0df3ba98e76eba3d0c0ca66d6", "_cell_guid": "66c57a1b-c8bc-415b-8103-a5a8bf552553"}, "cell_type": "code", "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "df = pd.DataFrame({'imp': lgb_models[0].feature_importance(importance_type='gain'), 'col':features2.columns})\n", "df = df.sort_values(['imp','col'], ascending=[True, False])[:30]\n", "_ = df.plot(kind='barh', x='col', y='imp', figsize=(7,12))"], "execution_count": null}, {"metadata": {"collapsed": true}, "cell_type": "code", "outputs": [], "source": ["df1 = pd.read_csv('submission.csv')\n", "df2 = pd.read_csv('../input/explore-stacking-another-hi-lo-and-clip-probs/stack_minmax_bestbase.csv')\n", "df2.columns = [x+'_' if x not in ['id'] else x for x in df2.columns]\n", "blend = pd.merge(df1, df2, how='left', on='id')\n", "for c in df1.columns:\n", "    if c != 'id':\n", "        blend[c] = (blend[c] * 0.5)  + (blend[c+'_'] * 0.5)\n", "blend = blend[df1.columns]\n", "blend['is_iceberg'] = blend['is_iceberg'].clip(0.+1e-15,1.-1e-15)\n", "blend.to_csv('blend1.csv', index=False)"], "execution_count": null}, {"metadata": {"collapsed": true}, "cell_type": "code", "outputs": [], "source": ["df1 = pd.read_csv('blend1.csv')\n", "df2 = pd.read_csv('../input/explore-stacking-another-hi-lo-and-clip-probs/stack_minmax_bestbase.csv')\n", "df2.columns = [x+'_' if x not in ['id'] else x for x in df2.columns]\n", "blend = pd.merge(df1, df2, how='left', on='id')\n", "for c in df1.columns:\n", "    if c != 'id':\n", "        blend[c] = (blend[c]  + blend[c+'_'])/2 + np.sqrt(blend[c] * blend[c+'_'])\n", "blend = blend[df1.columns]\n", "blend['is_iceberg'] = blend['is_iceberg'].clip(0.+1e-15,1.-1e-15)\n", "blend.to_csv('blend2.csv', index=False)"], "execution_count": null}], "nbformat_minor": 1, "nbformat": 4}